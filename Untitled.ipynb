{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90c162c8-ef52-4231-8576-f0313055e141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62149732-e7bc-4d9a-bc9d-26bc63dded95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Mediapipe\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f6236f8-e531-4ade-b1cb-e1af7f1f13b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a, b, c):\n",
    "    \"\"\"Calculates the angle at point 'b' given three points a, b, and c.\"\"\"\n",
    "    a = np.array(a) # First point (e.g., MCP)\n",
    "    b = np.array(b) # Mid point (e.g., PIP)\n",
    "    c = np.array(c) # End point (e.g., DIP)\n",
    "\n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle > 180.0:\n",
    "        angle = 360-angle\n",
    "        \n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "827b847c-15fa-4558-9cb4-f00c489b7b6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hand_landmarks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage within your Mediapipe loop:\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Assuming 'hand_landmarks' is the result from Mediapipe\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m landmarks \u001b[38;5;241m=\u001b[39m \u001b[43mhand_landmarks\u001b[49m\u001b[38;5;241m.\u001b[39mlandmark\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Index Finger Joints\u001b[39;00m\n\u001b[0;32m      6\u001b[0m mcp \u001b[38;5;241m=\u001b[39m [landmarks[\u001b[38;5;241m5\u001b[39m]\u001b[38;5;241m.\u001b[39mx, landmarks[\u001b[38;5;241m5\u001b[39m]\u001b[38;5;241m.\u001b[39my]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hand_landmarks' is not defined"
     ]
    }
   ],
   "source": [
    "# Example usage within your Mediapipe loop:\n",
    "# Assuming 'hand_landmarks' is the result from Mediapipe\n",
    "landmarks = hand_landmarks.landmark\n",
    "\n",
    "# Index Finger Joints\n",
    "mcp = [landmarks[5].x, landmarks[5].y]\n",
    "pip = [landmarks[6].x, landmarks[6].y]\n",
    "dip = [landmarks[7].x, landmarks[7].y]\n",
    "\n",
    "index_angle = calculate_angle(mcp, pip, dip)\n",
    "\n",
    "# Basic Correctness Check for 'L' (Index should be straight ~180)\n",
    "if index_angle > 160:\n",
    "    print(\"Index Finger: Correct (Straight)\")\n",
    "else:\n",
    "    print(\"Index Finger: Incorrect (Folded)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ec121ea-c467-4757-8133-6d4d47bdfa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Mediapipe\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.5)\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    a, b, c = np.array(a), np.array(b), np.array(c)\n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    return 360-angle if angle > 180.0 else angle\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "\n",
    "    # Flip and Convert to RGB\n",
    "    image = cv2.cvtColor(cv2.flip(frame, 1), cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            # Draw the skeleton on screen\n",
    "            mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "            \n",
    "            # Extract Landmarks\n",
    "            lm = hand_landmarks.landmark\n",
    "            \n",
    "            # Points for Index Finger (MCP: 5, PIP: 6, DIP: 7)\n",
    "            mcp = [lm[5].x, lm[5].y]\n",
    "            pip = [lm[6].x, lm[6].y]\n",
    "            dip = [lm[7].x, lm[7].y]\n",
    "\n",
    "            angle = calculate_angle(mcp, pip, dip)\n",
    "\n",
    "            # Display \"Correctness\" on screen\n",
    "            status = \"STRAIGHT\" if angle > 160 else \"BENT\"\n",
    "            color = (0, 255, 0) if status == \"STRAIGHT\" else (0, 0, 255)\n",
    "            \n",
    "            cv2.putText(image, f\"Index: {status} ({int(angle)})\", \n",
    "                        (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "\n",
    "    cv2.imshow('ASL Joint Checker', image)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8a1636b-e109-4ee0-a8aa-dff947f613c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Mediapipe\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.6)\n",
    "\n",
    "# Finger tip landmark indices\n",
    "TIP_IDS = [4, 8, 12, 16, 20]\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "def get_finger_states(lm):\n",
    "    \"\"\"\n",
    "    Returns list of finger states:\n",
    "    [thumb, index, middle, ring, pinky]\n",
    "    1 = open, 0 = closed\n",
    "    \"\"\"\n",
    "    fingers = []\n",
    "\n",
    "    # Thumb\n",
    "    fingers.append(1 if lm[4].x > lm[3].x else 0)\n",
    "\n",
    "    # Other fingers\n",
    "    for tip in TIP_IDS[1:]:\n",
    "        fingers.append(1 if lm[tip].y < lm[tip - 2].y else 0)\n",
    "\n",
    "    return fingers\n",
    "\n",
    "def detect_asl_letter(fingers):\n",
    "    \"\"\"\n",
    "    Rule-based ASL alphabet detection\n",
    "    \"\"\"\n",
    "    if fingers == [0,0,0,0,0]:\n",
    "        return 'A'\n",
    "    elif fingers == [1,0,0,0,0]:\n",
    "        return 'S'\n",
    "    elif fingers == [0,1,0,0,0]:\n",
    "        return 'D'\n",
    "    elif fingers == [0,1,1,0,0]:\n",
    "        return 'U'\n",
    "    elif fingers == [0,1,1,1,0]:\n",
    "        return 'W'\n",
    "    elif fingers == [1,1,0,0,0]:\n",
    "        return 'L'\n",
    "    elif fingers == [0,0,0,0,1]:\n",
    "        return 'I'\n",
    "    elif fingers == [1,0,0,0,1]:\n",
    "        return 'Y'\n",
    "    elif fingers == [0,1,1,1,1]:\n",
    "        return 'B'\n",
    "    elif fingers == [1,1,1,1,1]:\n",
    "        return 'OPEN'\n",
    "    else:\n",
    "        return '?'\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    image = cv2.cvtColor(cv2.flip(frame, 1), cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "\n",
    "            mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            lm = hand_landmarks.landmark\n",
    "            fingers = get_finger_states(lm)\n",
    "            letter = detect_asl_letter(fingers)\n",
    "\n",
    "            cv2.putText(image, f\"ASL: {letter}\", (20, 60),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,255,0), 3)\n",
    "\n",
    "    cv2.imshow(\"ASL Alphabet Detector\", image)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f807b352-a398-47ab-a08b-8f9e97cfa9f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python 3.10 (Mediapipe)",
   "language": "python",
   "name": "mp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
