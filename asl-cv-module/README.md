# ASL CV Module ðŸ¤Ÿ

Computer vision pipeline for real-time American Sign Language detection and feedback. Part of a Duolingo-style ASL learning web application.

## What This Module Does

Takes a webcam frame â†’ returns sign recognition + per-joint correctness score + human-readable feedback.

```
Camera Frame
    â†“
MediaPipe Holistic     â†’ 21+21+33 landmarks
    â†“
Feature Extraction     â†’ joint angles, positions, orientations (178 features)
    â†“
PyTorch Classifier     â†’ "This looks like sign A" (94% confidence)
    â†“
Scoring Engine         â†’ per-joint deviation from reference expert pose
    â†“
Feedback Generator     â†’ "Curl your thumb more" + green/orange/red joint colors
    â†“
FastAPI Response       â†’ JSON sent to frontend
```

## Project Structure

```
asl-cv-module/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ detector.py          # MediaPipe Holistic wrapper
â”‚   â”œâ”€â”€ extractor.py         # Feature engineering (angles, orientation)
â”‚   â””â”€â”€ scorer.py            # Joint-level correctness scoring
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ base.py              # Abstract classifier base class
â”‚   â”œâ”€â”€ static.py            # PyTorch MLP for letters (A-Z)
â”‚   â”œâ”€â”€ dynamic.py           # PyTorch LSTM for word signs
â”‚   â””â”€â”€ checkpoints/         # Saved model weights (gitignored)
â”œâ”€â”€ feedback/
â”‚   â”œâ”€â”€ generator.py         # Converts scores â†’ feedback messages
â”‚   â””â”€â”€ templates/signs.json # Sign-specific correction hints
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ references/letters/  # Expert pose JSON per sign
â”‚   â”œâ”€â”€ datasets/            # Training data (gitignored)
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ collect.py       # Record reference poses from webcam
â”‚       â””â”€â”€ preprocess.py    # Prepare training data
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ pipeline.py          # Orchestrates the full pipeline
â”‚   â”œâ”€â”€ router.py            # FastAPI endpoints
â”‚   â””â”€â”€ schemas.py           # Request/response JSON contract
â”œâ”€â”€ tests/                   # Pytest test suite
â”œâ”€â”€ API.md                   # Full API documentation for teammates
â”œâ”€â”€ Dockerfile
â””â”€â”€ requirements.txt
```

## Quick Start

```bash
# 1. Clone and install
git clone https://github.com/your-org/asl-cv-module
cd asl-cv-module
pip install -r requirements.txt

# 2. Record reference poses (do this for each sign)
python data/scripts/collect.py --sign A
python data/scripts/collect.py --sign B
# ... repeat for all signs

# 3. Start the API server
uvicorn api.router:app --reload --port 8000

# 4. Test it's working
curl http://localhost:8000/health
```

## Team Integration

See [API.md](API.md) for the full JSON contract.

**One-line summary for teammates:**
```
POST /analyze  â†’  { overall_score, messages, joint_colors, emoji, ... }
```

## Development

```bash
# Run tests
pytest tests/ -v

# Train static model (after collecting data)
python -c "
from models.static import StaticSignClassifier
import numpy as np

X_train = np.load('data/datasets/X_train.npy')
y_train = np.load('data/datasets/y_train.npy')
X_val   = np.load('data/datasets/X_val.npy')
y_val   = np.load('data/datasets/y_val.npy')

clf = StaticSignClassifier(num_classes=26)
clf.train_model(X_train, y_train, X_val, y_val, epochs=50)
"
```

## Tech Stack

| Component | Technology |
|---|---|
| Landmark detection | MediaPipe Holistic |
| Static sign model | PyTorch MLP |
| Dynamic sign model | PyTorch BiLSTM + Attention |
| API server | FastAPI + Uvicorn |
| Deployment | Docker + ONNX (planned) |

## Contributing

This module is part of a larger open-source ASL learning platform. Contributions welcome â€” see open issues for tasks.
